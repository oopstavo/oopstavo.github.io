---
title: 数据科学的基础统计和概率知识
categories:
  - Manual
date: 2020-06-11 20:37:19
tags:
    - cs
summary: 了解了统计之后，发现统计其实是一种世界观。
---
了解了统计之后，发现统计其实是一种世界观。

---

>统计推断和概率论的区别：
The basic problem that we study in probability is: Given a data generating process, what are the properities of the outcomes? 
The basic problem of statistical inference is the inverse of probability: Given the outcomes, what can we say about the process that generated the data?

概率论是统计推断的基础，在给定数据生成过程下观测、研究数据的性质；而统计推断则根据观测的数据，反向思考其数据生成过程。预测、分类、聚类、估计等，都是统计推断的特殊形式，强调对于数据生成过程的研究。

![Difference between sta and prob.](https://betterexplained.com/wp-content/uploads/2012/09/probability_vs_stats.png)

>### 平均数 Mean 

平均数没有你想象的那么简单。平均数是一个统计量，是试验后根据实际结果得到的样本的平均值。与之前相对应的，在概率论中的值叫期望。
** 平均数的意义是，对于数列<code>An</code>，用某一个常数<code>A</code>对数列中的每一项进行替换，形成的新数列结果上与旧数列等效。这个常数<code>A</code>就是数列<code>An</code>的平均数。**
常用到的平均数有三种，* 算术平均数 *，* 几何平均数*，还有*调和平均数*。

#### 算术平均数
算术平均数非常简单，就是对一个数列<code>An</code>中的所有项进行求和，然后除以数量。
$$\bar{x}=\frac{x_1+x_2+...+x_n}{n}$$
算术平均数是最常用的，也是最常用错的一个统计值。
算术平均数更少的收到随机因素的影响，但是更容易受到极端值的影响。所以在国际比赛的评分中，要去掉一个最高分，去掉一个最低分，然后再算平均分（裁剪平均值 Truncated mean）。

#### 几何平均数
几何平均数就是对数列<code>An</code>中的所有项相乘，然后再开<code>N</code>次方：
$$\bar{x}=\sqrt[n]{x_1x_2x_3...x_n}$$
几何平均数经常用来算平均增长率。在推荐系统中，其实也可以用来对同类商品进行排名。比如，有两款相机，一款的变焦为<code>200</code>，品质为<code>8</code>；另外一款的变焦为<code>250</code>，品质为<code>6</code>，对这两款相机排名的话，可以用几何平均数。第一款的结果为<code>40</code>，第二款的结果为<code>38.7</code>。

#### 调和平均数 Harmonic mean
调和平均数又称倒数平均数，是数列<code>An</code>中所有项的倒数的算术平均数的倒数。
$$H=\frac{n}{\frac{1}{x_1}+\frac{1}{x_2}+...+\frac{1}{x_n}}$$
调和平均数给了小值更大的权重。在数据科学中，F1 Score 的值就是准确率和召回率的调和平均数。

** * 平均数不等式：算术平均数>几何平均数>调和平均数 * **

>### 期望

期望是一种概率论概念。期望是实验前根据概率分布预测的样本的平均值，是上帝视角对实验结果的预知。实验进行无限多次的平均值会无限接近期望。期望就是平均数随样本趋于无穷的极限。  
$$E(X) = \sum_{k=1}^{\infty}x_kp_k$$

>### 方差和标准差

#### 方差 Variance
方差是用来衡量随机变量或一组数据的离散程度的量。概率论中，方差是用来随机变量和数学期望之间的偏离程度。在统计学中，方差是各个样本数据和平均数之间的偏离程度。
所以在概率论中的方差公式：
$$Var(X)=E\{\sum[X-E(X)]^2\}$$
在统计学中的方差公式：
总体方差公式：($$\mu$$为总体均值)
$$\sigma^2=\frac{\sum(X-\mu)^2}{N}$$
样本方差公式：($$\bar{x}$$为样本均值)
$$S^2=\frac{\sum(X-\bar{x})^2}{n-1}$$

为什么样本方差的分母需要<code>-1</code>呢？为了能够得到更准确的结论，需要在采集样本的时候需要做到样本之间相互独立，即样本之间应该没有任何联系，不能够通过某些样本来推测另一些样本。但是公式中样本平均值的引入，使得原本相互独立的样本，变得没有那么独立。因为可以通过平均值，和<code>n-1</code>个样本值，来推测出剩下的一个样本值，从而样本的自由度减少了1，也就是说只有<code>n-1</code>个相互独立的样本。所以分母需要做<code>-1</code>处理。这个处理叫做贝塞尔校正（Bessel's Correction）。并且样本平均值的引入，使得公式存在误差，会使样本方差变得比总体方差小，所以需要平衡。
如果不做贝塞尔校正的话，在样本量小的时候，样本方差会比全体方差偏小。在样本量大的时候，偏差逐渐减少，直到可以忽略不计。

全体方差是一个事实(fact)，样本方差是对事实的一个推测（Estimation)
贝塞尔校正的推倒： http://math.oxford.emory.edu/site/math117/besselCorrection/


#### 标准差 St


>### 常用公式

条件概率: $$P(B|A)=\frac{P(AB)}{P(A)}$$
乘法定则: $$P(A_1A_2...A_n)=P(A_n|A_1A_2...A_{n-1})P(A_{n-1}|A_1A_2...A_{n-2})...P(A_2|A_1)P(A_1)$$

---

贝叶斯公式: $$P(B_i|A)=\frac{P(A|B_i)P(B_i)}{\sum_{j=1}^nP(A|B_j)P(B_j)},i=1,2,...,n$$
当 n=2 时, $$P(A)=P(A|B)P(B)+P(A|\bar{B})P(\bar{B})$$

test
